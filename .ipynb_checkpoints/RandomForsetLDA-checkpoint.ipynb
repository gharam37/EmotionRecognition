{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s01\n",
      "Array of average Happy Sad accurecies for user s01\n",
      "Counter({60.0: 36, 40.0: 23, 80.0: 22, 20.0: 11, 100.0: 7, 0.0: 1})\n",
      "Happy Sad\n",
      "[57.6, 0.5672301587301587]\n",
      "Array of average All Emotions accurecies for user s01\n",
      "Counter({25.0: 26, 37.5: 25, 12.5: 21, 50.0: 15, 62.5: 7, 0.0: 6})\n",
      "Combined Emotions\n",
      "[30.375, 0.28735019841269843]\n",
      "Arousal 54.125\n",
      "Counter({50.0: 26, 62.5: 25, 75.0: 17, 37.5: 15, 25.0: 10, 87.5: 5, 12.5: 2})\n",
      "Valence 46.625\n",
      "Counter({50.0: 31, 37.5: 20, 25.0: 18, 62.5: 18, 75.0: 10, 12.5: 3})\n",
      "Arousal Valence\n",
      "[54.125, 46.625, 0.520705044955045, 0.4516088911088911]\n",
      "s02\n",
      "Array of average Happy Sad accurecies for user s02\n",
      "Counter({60.0: 41, 80.0: 36, 100.0: 12, 40.0: 6, 20.0: 4, 0.0: 1})\n",
      "Happy Sad\n",
      "[68.6, 0.7022777777777778]\n",
      "Array of average All Emotions accurecies for user s02\n",
      "Counter({37.5: 32, 25.0: 21, 50.0: 21, 12.5: 10, 75.0: 8, 62.5: 6, 87.5: 1, 0.0: 1})\n",
      "Combined Emotions\n",
      "[39.625, 0.37032665945165943]\n",
      "Arousal 58.75\n",
      "Counter({62.5: 29, 50.0: 24, 75.0: 19, 37.5: 14, 87.5: 8, 25.0: 4, 12.5: 1, 100.0: 1})\n",
      "Valence 72.25\n",
      "Counter({75.0: 34, 87.5: 24, 62.5: 22, 50.0: 7, 37.5: 6, 100.0: 6, 25.0: 1})\n",
      "Arousal Valence\n",
      "[58.75, 72.25, 0.5443813963813964, 0.7306292596292597]\n",
      "s03\n",
      "Array of average Happy Sad accurecies for user s03\n",
      "Counter({66.66666666666666: 45, 33.33333333333333: 34, 100.0: 12, 0.0: 9})\n",
      "Happy Sad\n",
      "[53.33333333333333, 0.509]\n",
      "Array of average All Emotions accurecies for user s03\n",
      "Counter({37.5: 28, 50.0: 26, 25.0: 18, 12.5: 11, 62.5: 8, 0.0: 5, 75.0: 4})\n",
      "Combined Emotions\n",
      "[37.375, 0.36814448051948057]\n",
      "Arousal 72.5\n",
      "Counter({75.0: 32, 87.5: 26, 62.5: 23, 50.0: 14, 100.0: 4, 37.5: 1})\n",
      "Valence 54.25\n",
      "Counter({50.0: 34, 62.5: 25, 75.0: 16, 37.5: 13, 25.0: 7, 87.5: 2, 12.5: 2, 100.0: 1})\n",
      "Arousal Valence\n",
      "[72.5, 54.25, 0.6691714119214117, 0.5553050838050838]\n",
      "s04\n",
      "Array of average Happy Sad accurecies for user s04\n",
      "Counter({50.0: 31, 33.33333333333333: 23, 66.66666666666666: 21, 16.666666666666664: 10, 83.33333333333334: 7, 0.0: 5, 100.0: 3})\n",
      "Happy Sad\n",
      "[47.66666666666667, 0.4676547619047619]\n",
      "Array of average All Emotions accurecies for user s04\n",
      "Counter({37.5: 30, 25.0: 29, 50.0: 20, 12.5: 9, 62.5: 6, 0.0: 3, 75.0: 3})\n",
      "Combined Emotions\n",
      "[35.625, 0.3499705988455987]\n",
      "Arousal 50.625\n",
      "Counter({50.0: 26, 62.5: 22, 37.5: 20, 25.0: 14, 75.0: 11, 87.5: 5, 12.5: 2})\n",
      "Valence 49.375\n",
      "Counter({50.0: 32, 62.5: 22, 37.5: 19, 25.0: 11, 75.0: 10, 12.5: 4, 87.5: 2})\n",
      "Arousal Valence\n",
      "[50.625, 49.375, 0.4888421855921855, 0.48948068598068595]\n",
      "s05\n",
      "Array of average Happy Sad accurecies for user s05\n",
      "Counter({83.33333333333334: 37, 66.66666666666666: 34, 100.0: 16, 50.0: 11, 33.33333333333333: 2})\n",
      "Happy Sad\n",
      "[75.66666666666666, 0.7508807118807118]\n",
      "Array of average All Emotions accurecies for user s05\n",
      "Counter({50.0: 27, 25.0: 24, 37.5: 22, 12.5: 14, 62.5: 10, 0.0: 3})\n",
      "Combined Emotions\n",
      "[35.75, 0.3370854076479076]\n",
      "Arousal 53.75\n",
      "Counter({62.5: 26, 50.0: 26, 37.5: 21, 75.0: 15, 25.0: 7, 87.5: 4, 12.5: 1})\n",
      "Valence 64.125\n",
      "Counter({75.0: 27, 62.5: 26, 50.0: 21, 37.5: 11, 87.5: 10, 100.0: 4, 25.0: 1})\n",
      "Arousal Valence\n",
      "[53.75, 64.125, 0.4951185481185483, 0.6327672327672327]\n",
      "s06\n",
      "Array of average Happy Sad accurecies for user s06\n",
      "Counter({50.0: 45, 75.0: 33, 100.0: 11, 25.0: 9, 0.0: 2})\n",
      "Happy Sad\n",
      "[60.5, 0.6066190476190476]\n",
      "Array of average All Emotions accurecies for user s06\n",
      "Counter({25.0: 30, 37.5: 29, 12.5: 19, 50.0: 13, 0.0: 6, 62.5: 2, 75.0: 1})\n",
      "Combined Emotions\n",
      "[29.25, 0.2732719155844156]\n",
      "Arousal 44.5\n",
      "Counter({50.0: 41, 25.0: 19, 37.5: 15, 62.5: 15, 75.0: 5, 12.5: 4, 0.0: 1})\n",
      "Valence 67.125\n",
      "Counter({75.0: 35, 62.5: 28, 50.0: 15, 87.5: 13, 37.5: 6, 100.0: 2, 25.0: 1})\n",
      "Arousal Valence\n",
      "[44.5, 67.125, 0.4220912420912421, 0.6719778554778553]\n",
      "s07\n",
      "Array of average Happy Sad accurecies for user s07\n",
      "Counter({60.0: 37, 80.0: 34, 40.0: 20, 100.0: 7, 20.0: 2})\n",
      "Happy Sad\n",
      "[64.8, 0.6315396825396825]\n",
      "Array of average All Emotions accurecies for user s07\n",
      "Counter({37.5: 33, 25.0: 29, 50.0: 18, 62.5: 9, 12.5: 9, 0.0: 2})\n",
      "Combined Emotions\n",
      "[35.375, 0.3316432872682873]\n",
      "Arousal 56.375\n",
      "Counter({62.5: 30, 50.0: 28, 37.5: 16, 75.0: 14, 87.5: 7, 25.0: 3, 12.5: 2})\n",
      "Valence 64.25\n",
      "Counter({75.0: 33, 62.5: 30, 50.0: 15, 87.5: 10, 37.5: 8, 12.5: 2, 100.0: 1, 25.0: 1})\n",
      "Arousal Valence\n",
      "[56.375, 64.25, 0.5248435175935176, 0.6365523643023642]\n",
      "s08\n",
      "Array of average Happy Sad accurecies for user s08\n",
      "Counter({80.0: 49, 60.0: 31, 100.0: 13, 40.0: 7})\n",
      "Happy Sad\n",
      "[73.6, 0.7181984126984128]\n",
      "Array of average All Emotions accurecies for user s08\n",
      "Counter({50.0: 29, 37.5: 25, 62.5: 17, 25.0: 16, 12.5: 6, 75.0: 4, 0.0: 3})\n",
      "Combined Emotions\n",
      "[42.25, 0.40334398934398935]\n",
      "Arousal 74.125\n",
      "Counter({75.0: 37, 87.5: 23, 62.5: 21, 50.0: 8, 100.0: 8, 37.5: 3})\n",
      "Valence 67.375\n",
      "Counter({75.0: 33, 62.5: 29, 87.5: 17, 50.0: 11, 37.5: 7, 25.0: 2, 100.0: 1})\n",
      "Arousal Valence\n",
      "[74.125, 67.375, 0.6738639693639692, 0.6696477688977689]\n",
      "s09\n",
      "Array of average Happy Sad accurecies for user s09\n",
      "Counter({50.0: 33, 66.66666666666666: 32, 33.33333333333333: 16, 83.33333333333334: 10, 16.666666666666664: 6, 100.0: 2, 0.0: 1})\n",
      "Happy Sad\n",
      "[54.49999999999999, 0.5522866762866763]\n",
      "Array of average All Emotions accurecies for user s09\n",
      "Counter({37.5: 30, 50.0: 28, 25.0: 16, 62.5: 12, 12.5: 11, 0.0: 2, 75.0: 1})\n",
      "Combined Emotions\n",
      "[38.875, 0.3666662157287157]\n",
      "Arousal 62.375\n",
      "Counter({75.0: 29, 62.5: 28, 50.0: 23, 37.5: 12, 87.5: 7, 100.0: 1})\n",
      "Valence 57.5\n",
      "Counter({50.0: 31, 62.5: 31, 75.0: 16, 37.5: 12, 87.5: 6, 25.0: 3, 12.5: 1})\n",
      "Arousal Valence\n",
      "[62.375, 57.5, 0.5787751692751693, 0.5802763070263071]\n",
      "s10\n",
      "Array of average Happy Sad accurecies for user s10\n",
      "Counter({75.0: 38, 50.0: 38, 100.0: 14, 25.0: 9, 0.0: 1})\n",
      "Happy Sad\n",
      "[63.75, 0.6214761904761904]\n",
      "Array of average All Emotions accurecies for user s10\n",
      "Counter({25.0: 28, 37.5: 25, 12.5: 22, 50.0: 12, 62.5: 8, 0.0: 4, 75.0: 1})\n",
      "Combined Emotions\n",
      "[30.875, 0.29393749999999996]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import collections\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def RandomForestLDA(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ArousalEncoded'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ValenceEncoded'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test , z_train,z_test= train_test_split(BandsFile, ValenceFile,ArousalFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "# LDA Classifier Arousal=z\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, z_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, z_train)  \n",
    "    z_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(z_test, z_predict)\n",
    "    #return f1 score and accurecies for valence and arousal\n",
    "    return [accuracy_score(z_test, z_predict)*100,accuracy_score(y_test, y_predict)*100\n",
    "            ,f1_score(z_test, z_predict, average='weighted'),\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "\n",
    "############### Happy And Sad ####################\n",
    "def RandomForestHS(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'HappyAndSadEncoded'+\".csv\")\n",
    "    SurveyFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'HS'+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "    while ((np.sum(y_train == 0) == 0) or (np.sum(y_train == 1) == 0)): #Don't Start training unless you have 2 classes.. happens with imbalance\n",
    "        print(\"here\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "#     print(cm)\n",
    "    return [accuracy_score(y_test, y_predict)*100,\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "\n",
    "############### All Emotions ####################\n",
    "def RandomForestCombined(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ValenceAndArousalEncoded'+\".csv\")\n",
    "    SurveyFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=15)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "#     print(cm)\n",
    "    return [accuracy_score(y_test, y_predict)*100,\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "    \n",
    "def Run100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    F1_ScoreArousal=[]\n",
    "    F1_ScoreValence=[]\n",
    "    for i in range (100):\n",
    "        RandomForest=RandomForestLDA(UserName,Window,StartTime,EndTime)\n",
    "        arousal+=[RandomForest[0]]\n",
    "        valence+=[RandomForest[1]]\n",
    "        F1_ScoreArousal+=[RandomForest[2]]\n",
    "        F1_ScoreValence+=[RandomForest[3]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "    return [np.mean(arousal),np.mean(valence),np.mean(F1_ScoreArousal),np.mean(F1_ScoreValence)];\n",
    "    \n",
    "\n",
    "    \n",
    "def RunCombined100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    Combined=[]\n",
    "    F1_ALL=[]\n",
    "    for i in range (100):\n",
    "        AllEmotions=RandomForestCombined(UserName,Window,StartTime,EndTime)\n",
    "        Combined+=[AllEmotions[0]]\n",
    "        F1_ALL+=[AllEmotions[1]]\n",
    "    print(\"Array of average All Emotions accurecies for user \"+UserName)\n",
    "    print(collections.Counter(Combined))\n",
    "    return [np.mean(Combined),np.mean(F1_ALL)];\n",
    "    \n",
    "def RunHS100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    Combined=[]\n",
    "    F1_HS=[]\n",
    "    for i in range (100):\n",
    "        HS=RandomForestHS(UserName,Window,StartTime,EndTime)\n",
    "        Combined+=[HS[0]]\n",
    "        F1_HS+=[HS[1]]\n",
    "    print(\"Array of average Happy Sad accurecies for user \"+UserName)\n",
    "    print(collections.Counter(Combined))\n",
    "    return [np.mean(Combined),np.mean(F1_HS)];\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    HSAccurecy=0;\n",
    "    HSF1=0;\n",
    "    CombinedAccurecy=0;\n",
    "    CombinedF1=0;\n",
    "    ValenceAccurecy=0;\n",
    "    ValenceF1=0;\n",
    "    ArousalAccurecy=0;\n",
    "    ArousalF1=0;\n",
    "    for i in range(1,10):\n",
    "        print(\"s0\"+str(i))\n",
    "        #Happy and Sad\n",
    "        var =RunHS100(\"s0\"+str(i))\n",
    "        print(\"Happy Sad\")\n",
    "        print(var)\n",
    "        HSAccurecy+=var[0]\n",
    "        HSF1+=var[1]\n",
    "        #All 4 Emotions\n",
    "        var1 =RunCombined100(\"s0\"+str(i))\n",
    "        print(\"Combined Emotions\")\n",
    "        print(var1)\n",
    "        CombinedAccurecy+=var1[0]\n",
    "        CombinedF1+=var1[1]\n",
    "        #Seperated Valence and Arousal\n",
    "        var2=Run100(\"s0\"+str(i))\n",
    "        print(\"Arousal Valence\")\n",
    "        print(var2)\n",
    "        ArousalAccurecy+=var2[0]\n",
    "        ValenceAccurecy+=var2[1]\n",
    "        ArousalF1+=var2[2]\n",
    "        ValenceF1+=var2[3]\n",
    "    for i in range(10,33):\n",
    "        print(\"s\"+str(i))\n",
    "        #Happy and Sad\n",
    "        if not (\"s\"+str(i) == \"s31\"):\n",
    "            var =RunHS100(\"s\"+str(i))\n",
    "            print(\"Happy Sad\")\n",
    "            print(var)\n",
    "            HSAccurecy+=var[0]\n",
    "            HSF1+=var[1]\n",
    "        #All 4 Emotions\n",
    "        var1 =RunCombined100(\"s\"+str(i))\n",
    "        print(\"Combined Emotions\")\n",
    "        print(var1)\n",
    "        CombinedAccurecy+=var1[0]\n",
    "        CombinedF1+=var1[1]\n",
    "        #Seperated Valence and Arousal\n",
    "        var2=Run100(\"s\"+str(i))\n",
    "        print(\"Arousal Valence\")\n",
    "        print(var2)\n",
    "        ArousalAccurecy+=var2[0]\n",
    "        ValenceAccurecy+=var2[1]\n",
    "        ArousalF1+=var2[2]\n",
    "    print(\"Accurecy happy sad for 31 users \"+str(HSAccurecy/31))\n",
    "    print(\"F1 happy sad for 31 users \"+str(HSF1/31))\n",
    "    print(\"Accurecy Combined sad for 32 users\"+str(CombinedAccurecy/32))\n",
    "    print(\"F1 Combined sad for  32 users \"+str(CombinedF1/32))\n",
    "    print(\"Accurecy Valence for  32 users \"+str(ValenceAccurecy/32))\n",
    "    print(\"F1 Valence for 32 users \"+str(ValenceF1/32))\n",
    "    print(\"Accurecy Arousal for  32 users \"+str(ArousalAccurecy/32))\n",
    "    print(\"F1 Arousal for  32 users \"+str(ArousalF1/32))\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
