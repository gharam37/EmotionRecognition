{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s01\n",
      "Array of average Happy Sad accurecies for user s01\n",
      "Counter({60.0: 36, 40.0: 33, 80.0: 17, 20.0: 9, 100.0: 5})\n",
      "Happy Sad\n",
      "[55.2, 0.5372539682539681]\n",
      "Array of average All Emotions accurecies for user s01\n",
      "Counter({25.0: 33, 12.5: 20, 37.5: 17, 50.0: 17, 0.0: 6, 62.5: 5, 75.0: 2})\n",
      "Combined Emotions\n",
      "[30.25, 0.28754365079365085]\n",
      "Arousal 53.5\n",
      "Counter({62.5: 28, 50.0: 24, 37.5: 21, 75.0: 11, 25.0: 10, 87.5: 5, 100.0: 1})\n",
      "Valence 44.5\n",
      "Counter({37.5: 30, 50.0: 29, 62.5: 18, 25.0: 17, 75.0: 4, 12.5: 2})\n",
      "Arousal Valence\n",
      "[53.5, 44.5, 0.4988936618936618, 0.4398903318903319]\n",
      "s10\n",
      "Array of average Happy Sad accurecies for user s10\n",
      "Counter({75.0: 42, 50.0: 36, 100.0: 12, 25.0: 10})\n",
      "Happy Sad\n",
      "[64.0, 0.6274761904761904]\n",
      "Array of average All Emotions accurecies for user s10\n",
      "Counter({37.5: 34, 25.0: 28, 12.5: 18, 50.0: 12, 0.0: 7, 75.0: 1})\n",
      "Combined Emotions\n",
      "[28.75, 0.2716547619047619]\n",
      "Arousal 50.0\n",
      "Counter({37.5: 27, 50.0: 25, 62.5: 19, 75.0: 12, 25.0: 10, 87.5: 3, 12.5: 3, 100.0: 1})\n",
      "Valence 57.625\n",
      "Counter({62.5: 29, 50.0: 27, 75.0: 18, 37.5: 14, 87.5: 7, 25.0: 4, 12.5: 1})\n",
      "Arousal Valence\n",
      "[50.0, 57.625, 0.46794841269841264, 0.5699360361860362]\n",
      "Accurecy happy sad for first 30 59.6\n",
      "F1 happy sad for first 30 0.5823650793650792\n",
      "Accurecy Combined sad for first 30 29.5\n",
      "F1 Combined sad for first 30 0.2795992063492064\n",
      "Accurecy Valence for first 30 51.0625\n",
      "F1 Valence for first 30 0.21994516594516594\n",
      "Accurecy Arousal for first 30 51.75\n",
      "F1 Arousal for first 30 0.48342103729603725\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import collections\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def RandomForestLDA(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ArousalEncoded'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ValenceEncoded'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test , z_train,z_test= train_test_split(BandsFile, ValenceFile,ArousalFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "# LDA Classifier Arousal=z\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, z_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, z_train)  \n",
    "    z_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(z_test, z_predict)\n",
    "    #return f1 score and accurecies for valence and arousal\n",
    "    return [accuracy_score(z_test, z_predict)*100,accuracy_score(y_test, y_predict)*100\n",
    "            ,f1_score(z_test, z_predict, average='weighted'),\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "\n",
    "############### Happy And Sad ####################\n",
    "def RandomForestHS(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'HappyAndSadEncoded'+\".csv\")\n",
    "    SurveyFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'HS'+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "    while ((np.sum(y_train == 0) == 0) or (np.sum(y_train == 1) == 0)): #Don't Start training unless you have 2 classes.. happens with imbalance\n",
    "        print(\"here\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=20)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "#     print(cm)\n",
    "    return [accuracy_score(y_test, y_predict)*100,\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "\n",
    "############### All Emotions ####################\n",
    "def RandomForestCombined(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",UserName, 'ValenceAndArousalEncoded'+\".csv\")\n",
    "    SurveyFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(BandsFile, SurveyFile, test_size=0.2)\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=15)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "#     print(cm)\n",
    "    return [accuracy_score(y_test, y_predict)*100,\n",
    "            f1_score(y_test, y_predict, average='weighted')]\n",
    "    \n",
    "def Run100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    F1_ScoreArousal=[]\n",
    "    F1_ScoreValence=[]\n",
    "    for i in range (100):\n",
    "        RandomForest=RandomForestLDA(UserName,Window,StartTime,EndTime)\n",
    "        arousal+=[RandomForest[0]]\n",
    "        valence+=[RandomForest[1]]\n",
    "        F1_ScoreArousal+=[RandomForest[2]]\n",
    "        F1_ScoreValence+=[RandomForest[3]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "    return [np.mean(arousal),np.mean(valence),np.mean(F1_ScoreArousal),np.mean(F1_ScoreValence)];\n",
    "    \n",
    "\n",
    "    \n",
    "def RunCombined100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    Combined=[]\n",
    "    F1_ALL=[]\n",
    "    for i in range (100):\n",
    "        AllEmotions=RandomForestCombined(UserName,Window,StartTime,EndTime)\n",
    "        Combined+=[AllEmotions[0]]\n",
    "        F1_ALL+=[AllEmotions[1]]\n",
    "    print(\"Array of average All Emotions accurecies for user \"+UserName)\n",
    "    print(collections.Counter(Combined))\n",
    "    return [np.mean(Combined),np.mean(F1_ALL)];\n",
    "    \n",
    "def RunHS100(UserName,Window=256,StartTime=0,EndTime=63):\n",
    "    Combined=[]\n",
    "    F1_HS=[]\n",
    "    for i in range (100):\n",
    "        HS=RandomForestHS(UserName,Window,StartTime,EndTime)\n",
    "        Combined+=[HS[0]]\n",
    "        F1_HS+=[HS[1]]\n",
    "    print(\"Array of average Happy Sad accurecies for user \"+UserName)\n",
    "    print(collections.Counter(Combined))\n",
    "    return [np.mean(Combined),np.mean(F1_HS)];\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    HSAccurecy=0;\n",
    "    HSF1=0;\n",
    "    CombinedAccurecy=0;\n",
    "    CombinedF1=0;\n",
    "    ValenceAccurecy=0;\n",
    "    ValenceF1=0;\n",
    "    ArousalAccurecy=0;\n",
    "    ArousalF1=0;\n",
    "    for i in range(1,10):\n",
    "        print(\"s0\"+str(i))\n",
    "        #Happy and Sad\n",
    "        var =RunHS100(\"s0\"+str(i))\n",
    "        print(\"Happy Sad\")\n",
    "        print(var)\n",
    "        HSAccurecy+=var[0]\n",
    "        HSF1+=var[1]\n",
    "        #All 4 Emotions\n",
    "        var1 =RunCombined100(\"s0\"+str(i))\n",
    "        print(\"Combined Emotions\")\n",
    "        print(var1)\n",
    "        CombinedAccurecy+=var1[0]\n",
    "        CombinedF1+=var1[1]\n",
    "        #Seperated Valence and Arousal\n",
    "        var2=Run100(\"s0\"+str(i))\n",
    "        print(\"Arousal Valence\")\n",
    "        print(var2)\n",
    "        ArousalAccurecy+=var2[0]\n",
    "        ValenceAccurecy+=var2[1]\n",
    "        ArousalF1+=var2[2]\n",
    "        ValenceF1+=var2[3]\n",
    "    for i in range(10,31):\n",
    "        print(\"s\"+str(i))\n",
    "        #Happy and Sad\n",
    "        var =RunHS100(\"s\"+str(i))\n",
    "        print(\"Happy Sad\")\n",
    "        print(var)\n",
    "        HSAccurecy+=var[0]\n",
    "        HSF1+=var[1]\n",
    "        #All 4 Emotions\n",
    "        var1 =RunCombined100(\"s\"+str(i))\n",
    "        print(\"Combined Emotions\")\n",
    "        print(var1)\n",
    "        CombinedAccurecy+=var1[0]\n",
    "        CombinedF1+=var1[1]\n",
    "        #Seperated Valence and Arousal\n",
    "        var2=Run100(\"s\"+str(i))\n",
    "        print(\"Arousal Valence\")\n",
    "        print(var2)\n",
    "        ArousalAccurecy+=var2[0]\n",
    "        ValenceAccurecy+=var2[1]\n",
    "        ArousalF1+=var2[2]\n",
    "    print(\"Accurecy happy sad for first 30 \"+str(HSAccurecy/30))\n",
    "    print(\"F1 happy sad for first 30 \"+str(HSF1/30))\n",
    "    print(\"Accurecy Combined sad for first 30 \"+str(CombinedAccurecy/30))\n",
    "    print(\"F1 Combined sad for first 30 \"+str(CombinedF1/30))\n",
    "    print(\"Accurecy Valence for first 30 \"+str(ValenceAccurecy/30))\n",
    "    print(\"F1 Valence for first 30 \"+str(ValenceF1/30))\n",
    "    print(\"Accurecy Arousal for first 30 \"+str(ArousalAccurecy/30))\n",
    "    print(\"F1 Arousal for first 30 \"+str(ArousalF1/30))\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
