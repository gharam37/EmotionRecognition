{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal 57.1625\n",
      "Counter({62.5: 338, 50.0: 318, 75.0: 150, 37.5: 130, 87.5: 38, 25.0: 22, 12.5: 3, 100.0: 1})\n",
      "Valence 36.975\n",
      "Counter({37.5: 303, 25.0: 289, 50.0: 208, 62.5: 87, 12.5: 84, 75.0: 20, 0.0: 9})\n",
      "Arousal 56.95\n",
      "Counter({62.5: 344, 50.0: 307, 75.0: 153, 37.5: 122, 25.0: 35, 87.5: 30, 100.0: 5, 12.5: 4})\n",
      "Valence 37.575\n",
      "Counter({37.5: 325, 25.0: 263, 50.0: 223, 62.5: 82, 12.5: 75, 75.0: 19, 0.0: 11, 87.5: 2})\n",
      "Arousal 57.7125\n",
      "Counter({62.5: 342, 50.0: 270, 75.0: 180, 37.5: 141, 87.5: 36, 25.0: 27, 12.5: 2, 100.0: 2})\n",
      "Valence 36.8375\n",
      "Counter({37.5: 316, 25.0: 277, 50.0: 227, 12.5: 87, 62.5: 69, 75.0: 14, 0.0: 7, 87.5: 3})\n",
      "Arousal 57.25\n",
      "Counter({62.5: 358, 50.0: 293, 75.0: 152, 37.5: 127, 87.5: 33, 25.0: 30, 100.0: 4, 12.5: 2, 0.0: 1})\n",
      "Valence 37.35\n",
      "Counter({37.5: 318, 25.0: 244, 50.0: 216, 12.5: 97, 62.5: 94, 75.0: 18, 0.0: 12, 87.5: 1})\n",
      "Arousal 56.125\n",
      "Counter({50.0: 322, 62.5: 308, 75.0: 163, 37.5: 146, 25.0: 35, 87.5: 24, 100.0: 1, 0.0: 1})\n",
      "Valence 36.325\n",
      "Counter({37.5: 334, 25.0: 246, 50.0: 213, 12.5: 110, 62.5: 72, 75.0: 15, 0.0: 10})\n",
      "Arousal 57.4375\n",
      "Counter({62.5: 323, 50.0: 284, 75.0: 194, 37.5: 134, 25.0: 32, 87.5: 29, 12.5: 3, 100.0: 1})\n",
      "Valence 36.225\n",
      "Counter({37.5: 315, 25.0: 271, 50.0: 219, 12.5: 99, 62.5: 68, 75.0: 16, 0.0: 12})\n",
      "Arousal 56.9375\n",
      "Counter({62.5: 341, 50.0: 289, 75.0: 166, 37.5: 141, 25.0: 30, 87.5: 28, 12.5: 3, 100.0: 2})\n",
      "Valence 37.325\n",
      "Counter({37.5: 292, 25.0: 263, 50.0: 241, 12.5: 94, 62.5: 76, 75.0: 22, 0.0: 10, 87.5: 2})\n",
      "Arousal 56.5625\n",
      "Counter({62.5: 332, 50.0: 308, 75.0: 158, 37.5: 133, 25.0: 36, 87.5: 29, 12.5: 3, 100.0: 1})\n",
      "Valence 37.175\n",
      "Counter({37.5: 306, 25.0: 288, 50.0: 210, 12.5: 84, 62.5: 82, 75.0: 22, 0.0: 6, 87.5: 2})\n",
      "Arousal 56.4125\n",
      "Counter({62.5: 349, 50.0: 297, 75.0: 148, 37.5: 138, 25.0: 38, 87.5: 24, 100.0: 4, 12.5: 2})\n",
      "Valence 36.5625\n",
      "Counter({37.5: 303, 25.0: 290, 50.0: 187, 12.5: 101, 62.5: 92, 75.0: 20, 0.0: 6, 87.5: 1})\n",
      "Arousal 56.7875\n",
      "Counter({62.5: 335, 50.0: 280, 75.0: 173, 37.5: 138, 25.0: 41, 87.5: 28, 12.5: 2, 100.0: 2, 0.0: 1})\n",
      "Valence 38.0875\n",
      "Counter({37.5: 340, 50.0: 235, 25.0: 226, 62.5: 97, 12.5: 83, 75.0: 10, 0.0: 8, 87.5: 1})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    " \n",
    "def SVMPCA(Components):\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",\"s01\", 'ArousalEncoded'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',')\n",
    "    file_path = os.path.join(\"ChannelsExtracted\",\"s01\", 'ValenceEncoded'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',')\n",
    "    BandsFile = np.genfromtxt('training/s013035train.csv',delimiter=',')\n",
    "#     print(\"Valence \\n \")\n",
    "#     print(\"Split the data into training/testing sets \\n\")\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test,z_train,z_test = train_test_split(BandsFile, ValenceFile,ArousalFile, test_size=0.2)\n",
    "#     print(\"Feature Scaling \\n\")\n",
    "#     Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "#     print(\"Applying PCA to select features \\n\")\n",
    "    \n",
    "    # PCA to select features\n",
    "    pca = PCA(n_components=Components, svd_solver='full')\n",
    "    pca.fit(BandsFile)\n",
    "    BandsFile = pca.transform(BandsFile)\n",
    "    #explained_variance=pca.explained_variance_ratio_\n",
    "    \n",
    "#     print(\"Applying SVM PCA classifier \\n\")\n",
    "    # SVM Classifier\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    #print(cm)\n",
    "#     print(\"Accuracy score of Valence SVM-PCA\")\n",
    "#     print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "#     print(\"Applying PCA to select features \\n\")\n",
    "    \n",
    "    # PCA to select features\n",
    "    pca = PCA(n_components=Components, svd_solver='full')\n",
    "    pca.fit(BandsFile)\n",
    "    BandsFile = pca.transform(BandsFile)\n",
    "    #explained_variance=pca.explained_variance_ratio_\n",
    "    \n",
    "#     print(\"Applying SVM classifier \\n\")\n",
    "    # SVM Classifier\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, z_train)\n",
    "    z_predict_0 = clf.predict(X_test)\n",
    "    cm = confusion_matrix(z_test, z_predict_0)\n",
    "    #print(cm)\n",
    "#     print(\"Accuracy score of Arousal SVM-PCA\")\n",
    "#     print(accuracy_score(z_test, z_predict_0)*100)\n",
    "    return [accuracy_score(z_test, z_predict_0)*100,accuracy_score(y_test, y_predict)*100]\n",
    "#     print(\"Valence test\")\n",
    "#     for i in range (len(y_test)):\n",
    "#         print(y_test[i])\n",
    "#     print(\"Valence Train\")\n",
    "#     for i in range (len(y_train)):\n",
    "#         print(y_train[i])\n",
    "#     print(\"Valence predict\")\n",
    "#     for i in range (len(y_predict)):\n",
    "#         print(y_predict[i])\n",
    "    \n",
    "\n",
    "\n",
    "def Run1000(Components):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    for i in range (1000):\n",
    "        svmpca=SVMPCA(Components)\n",
    "        arousal+=[svmpca[0]]\n",
    "        valence+=[svmpca[1]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "#     return arousal,valence\n",
    "        \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(10):\n",
    "        Run1000(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
