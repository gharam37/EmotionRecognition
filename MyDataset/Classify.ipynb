{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Arousal 66.8\n",
      "Counter({66.66666666666666: 35, 60.0: 22, 73.33333333333333: 18, 80.0: 10, 53.333333333333336: 8, 86.66666666666667: 4, 46.666666666666664: 2, 40.0: 1})\n",
      "Valence 79.66666666666667\n",
      "Counter({80.0: 25, 73.33333333333333: 20, 86.66666666666667: 19, 93.33333333333333: 17, 66.66666666666666: 13, 60.0: 5, 100.0: 1})\n",
      "Emotion 79.66666666666667\n",
      "Counter({80.0: 25, 73.33333333333333: 20, 86.66666666666667: 19, 93.33333333333333: 17, 66.66666666666666: 13, 60.0: 5, 100.0: 1})\n",
      "[66.8, 79.66666666666667, 79.66666666666667, 0.6619915886558814, 0.7966710005904717, 0.7966710005904717]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import collections\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def SVM(UserName,Window=256,StartTime=0,EndTime=180):\n",
    "    file_path = os.path.join(UserName, 'MultipledValence'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'MultipledArousal'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'MultipledEmotions'+\".csv\")\n",
    "    Emotions =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'Multiplied'+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test , z_train,z_test,k_train,k_test= train_test_split(BandsFile, ValenceFile,ArousalFile,Emotions, test_size=0.2)\n",
    "\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "    \n",
    "# SVM Classifier Valence\n",
    "    clf = SVC(kernel = 'linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \t\n",
    "# SVM Classifier Arousal\n",
    "    clf = SVC(kernel = 'linear')\n",
    "    clf.fit(X_train, z_train)\n",
    "    z_predict = clf.predict(X_test)\n",
    "# SVM Classifier Emotions\n",
    "    clf = SVC(kernel = 'linear')\n",
    "    clf.fit(X_train, k_train)\n",
    "    k_predict = clf.predict(X_test)\n",
    "    return [accuracy_score(z_test, z_predict)*100,accuracy_score(y_test, y_predict)*100,accuracy_score(k_test, k_predict)*100\n",
    "            ,f1_score(z_test, z_predict, average='weighted'),\n",
    "            f1_score(y_test, y_predict, average='weighted'),f1_score(k_test, k_predict, average='weighted')]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################### SVM PCA ############################33\n",
    "def SVMPCA(UserName,Components=10,Window=256,StartTime=0,EndTime=180):\n",
    "    file_path = os.path.join(UserName, 'ArousalEncoded'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'ValenceEncoded'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'Emotions'+\".csv\")\n",
    "    Emotions =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test , z_train,z_test,k_train,k_test= train_test_split(BandsFile, ValenceFile,ArousalFile,Emotions, test_size=0.2)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    # PCA to select features\n",
    "    pca = PCA(n_components=Components, svd_solver='full')\n",
    "    pca.fit(BandsFile)\n",
    "    BandsFile = pca.transform(BandsFile)\n",
    "    #Predict Valence SVM and PCA\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    #Predict Arousal SVM and PCA\n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "        \n",
    "    # PCA to select features\n",
    "    pca = PCA(n_components=Components, svd_solver='full')\n",
    "    pca.fit(BandsFile)\n",
    "    BandsFile = pca.transform(BandsFile)\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, z_train)\n",
    "    z_predict = clf.predict(X_test)\n",
    "    \n",
    "    #Predict Emotion SVM and PCA\n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "        \n",
    "    # PCA to select features\n",
    "    pca = PCA(n_components=Components, svd_solver='full')\n",
    "    pca.fit(BandsFile)\n",
    "    BandsFile = pca.transform(BandsFile)\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, k_train)\n",
    "    k_predict = clf.predict(X_test)\n",
    "    return [accuracy_score(z_test, z_predict)*100,accuracy_score(y_test, y_predict)*100,accuracy_score(k_test, k_predict)*100\n",
    "            ,f1_score(z_test, z_predict, average='weighted'),\n",
    "            f1_score(y_test, y_predict, average='weighted'),f1_score(k_test, k_predict, average='weighted')]\n",
    "\n",
    "################### Random Forest ################\n",
    "def RandomForestLDA(UserName,Components=10,Window=256,StartTime=0,EndTime=180):\n",
    "    file_path = os.path.join(UserName, 'ArousalEncoded'+\".csv\")\n",
    "    ArousalFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'ValenceEncoded'+\".csv\")\n",
    "    ValenceFile =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    file_path = os.path.join(UserName, 'Emotions'+\".csv\")\n",
    "    Emotions =  np.genfromtxt(fname=file_path,delimiter=',').astype(int)\n",
    "    BandsFile = np.genfromtxt('training/'+str(StartTime)+str(EndTime)+'/'+str(Window)+UserName+'.csv',delimiter=',')\n",
    "    X_train, X_test, y_train, y_test , z_train,z_test,k_train,k_test= train_test_split(BandsFile, ValenceFile,ArousalFile,Emotions, test_size=0.2)\n",
    "\n",
    "# Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)  \t\n",
    "# LDA Classifier Valence=y\n",
    "    lda = LDA(n_components=Components)  \n",
    "    X_train = lda.fit_transform(X_train, y_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_predict = classifier.predict(X_test)\n",
    "# LDA Classifier Arousal=z\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lda = LDA(n_components=Components)  \n",
    "    X_train = lda.fit_transform(X_train, z_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, z_train)  \n",
    "    z_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(z_test, z_predict)\n",
    "# LDA Classifier Emotions=k\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    lda = LDA(n_components=Components)  \n",
    "    X_train = lda.fit_transform(X_train, k_train)  \n",
    "    X_test = lda.transform(X_test)  \n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    classifier.fit(X_train, k_train)  \n",
    "    k_predict = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(k_test, k_predict)\n",
    "    #return f1 score and accurecies for valence and arousal\n",
    "    return [accuracy_score(z_test, z_predict)*100,accuracy_score(y_test, y_predict)*100,accuracy_score(k_test, k_predict)*100\n",
    "            ,f1_score(z_test, z_predict, average='weighted'),\n",
    "            f1_score(y_test, y_predict, average='weighted'),f1_score(k_test, k_predict, average='weighted')]\n",
    "\n",
    "\n",
    "\n",
    "################ Run SVM classifier 100 times #####################\n",
    "def RunSVM100(UserName,Window=256,StartTime=0,EndTime=180):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    emotion=[]\n",
    "    F1_ScoreArousal=[]\n",
    "    F1_ScoreValence=[]\n",
    "    F1_ScoreEmotion=[]\n",
    "    for i in range (100):\n",
    "        svm=SVM(UserName,Window,StartTime,EndTime)\n",
    "        arousal+=[svm[0]]\n",
    "        valence+=[svm[1]]\n",
    "        emotion+=[svm[2]]\n",
    "        F1_ScoreArousal+=[svm[3]]\n",
    "        F1_ScoreValence+=[svm[4]]\n",
    "        F1_ScoreEmotion+=[svm[5]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "    print(\"Emotion \"+str(np.mean(emotion)))\n",
    "    print(collections.Counter(emotion))\n",
    "    return [np.mean(arousal),np.mean(valence),np.mean(emotion),\n",
    "            np.mean(F1_ScoreArousal),np.mean(F1_ScoreValence),np.mean(F1_ScoreEmotion)];\n",
    "################# Run SVM PCA 100 #######################\n",
    "\n",
    "def RunSVMPCA100(UserName,Components=10,Window=256,StartTime=0,EndTime=180):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    emotion=[]\n",
    "    F1_ScoreArousal=[]\n",
    "    F1_ScoreValence=[]\n",
    "    F1_ScoreEmotion=[]\n",
    "    for i in range (100):\n",
    "        svm=SVMPCA(UserName,Components,Window,StartTime,EndTime)\n",
    "        arousal+=[svm[0]]\n",
    "        valence+=[svm[1]]\n",
    "        emotion+=[svm[2]]\n",
    "        F1_ScoreArousal+=[svm[3]]\n",
    "        F1_ScoreValence+=[svm[4]]\n",
    "        F1_ScoreEmotion+=[svm[5]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "    print(\"Emotion \"+str(np.mean(emotion)))\n",
    "    print(collections.Counter(emotion))\n",
    "    return [np.mean(arousal),np.mean(valence),np.mean(emotion),\n",
    "            np.mean(F1_ScoreArousal),np.mean(F1_ScoreValence),np.mean(F1_ScoreEmotion)];\n",
    "\n",
    "\n",
    "############ Run Random forest LDA 100 ###############\n",
    "\n",
    "def RunRandomLDA100(UserName,Components=10,Window=256,StartTime=0,EndTime=180):\n",
    "    arousal=[]\n",
    "    valence=[]\n",
    "    emotion=[]\n",
    "    F1_ScoreArousal=[]\n",
    "    F1_ScoreValence=[]\n",
    "    F1_ScoreEmotion=[]\n",
    "    for i in range (100):\n",
    "        RandomForest=RandomForestLDA(UserName,Components,Window,StartTime,EndTime)\n",
    "        arousal+=[RandomForest[0]]\n",
    "        valence+=[RandomForest[1]]\n",
    "        emotion+=[RandomForest[2]]\n",
    "        F1_ScoreArousal+=[RandomForest[3]]\n",
    "        F1_ScoreValence+=[RandomForest[4]]\n",
    "        F1_ScoreEmotion+=[RandomForest[5]]\n",
    "    print(\"Arousal \"+str(np.mean(arousal)))\n",
    "    print(collections.Counter(arousal))\n",
    "    print(\"Valence \"+str(np.mean(valence)))\n",
    "    print(collections.Counter(valence))\n",
    "    print(\"Emotion \"+str(np.mean(emotion)))\n",
    "    print(collections.Counter(emotion))\n",
    "    return [np.mean(arousal),np.mean(valence),np.mean(emotion),\n",
    "            np.mean(F1_ScoreArousal),np.mean(F1_ScoreValence),np.mean(F1_ScoreEmotion)];    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################Main#########################\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"SVM\")\n",
    "    print(RunSVM100(\"Mostafa\",128,30,90))\n",
    "#     print(\"SVM AND PCA\")\n",
    "#     print(RunSVMPCA100(\"Tarek\",Components=10,Window=256,StartTime=60,EndTime=120))\n",
    "#     print(\"Random Forest\")\n",
    "#     print(RunRandomLDA100(\"Tarek\",Components=5,Window=256,StartTime=60,EndTime=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
